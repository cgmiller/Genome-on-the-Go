{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgmiller/Genome-on-the-Go/blob/main/Genome_on_the_Go_Workshop_12Feb2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWlrLf3d2Avu"
      },
      "source": [
        "# ðŸ§¬ Nanopore Sequencing Analysis: Chloroplast Genome\n",
        "**Student Workshop Notebook**\n",
        "\n",
        "## Overview\n",
        "In this notebook, we will process raw sequencing data from an **Oxford Nanopore MinION** sequencer.\n",
        "\n",
        "## Prerequisites\n",
        "You must have the following two files ready to upload:\n",
        "1.  **Sequencing Data:** A `.fastq` file containing your raw reads.\n",
        "2.  **Reference Genome:** A `.fasta` file of the chloroplast genome you expect to find (e.g., *Arabidopsis thaliana* chloroplast).\n",
        "\n",
        "## Workflow\n",
        "1.  **Setup:** Install bioinformatics tools.\n",
        "2.  **Upload:** Load your real experimental data.\n",
        "3.  **QC & Stats:** Assess the quality of your sequencing run.\n",
        "4.  **Filtering:** Remove short or low-quality reads.\n",
        "5.  **Mapping:** Align reads to your reference genome.\n",
        "6.  **Consensus / Genome Assembly:** Generate the final biological sequence.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDHMbbSC2Avw"
      },
      "source": [
        "## Part 1: Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhU_hbNd2Avw"
      },
      "outputs": [],
      "source": [
        "# @title Step 1: Install Libraries and Tools\n",
        "# Installing Biopython (Python library) and Minimap2/Samtools/Bcftools (Bioinformatics software)\n",
        "!pip install biopython pandas seaborn matplotlib\n",
        "!apt-get install minimap2 samtools bcftools\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from Bio import SeqIO\n",
        "from google.colab import files\n",
        "\n",
        "print(\"âœ… Environment ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAOyHyhh2Avx"
      },
      "source": [
        "## Part 2: Upload Your Data\n",
        "\n",
        "**Instructions:**\n",
        "1. Run the cell below.\n",
        "2. Click the **'Choose Files'** button.\n",
        "3. Upload your `.fastq` file AND your `.fasta` reference file.\n",
        "4. The code will automatically rename them to standard names so the rest of the notebook works smoothly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYSBkIIr2Avx"
      },
      "outputs": [],
      "source": [
        "# @title Step 2: Upload Data\n",
        "uploaded = files.upload()\n",
        "\n",
        "# DEFINE STANDARD FILENAMES\n",
        "reads_filename = \"chloroplast_reads.fastq\"\n",
        "ref_filename = \"chloroplast_reference.fasta\"\n",
        "\n",
        "# LOGIC TO RENAME UPLOADED FILES\n",
        "print(\"\\nProcessing uploads...\")\n",
        "found_reads = False\n",
        "found_ref = False\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith(\".fastq\") or filename.endswith(\".fq\"):\n",
        "        os.rename(filename, reads_filename)\n",
        "        print(f\"âœ… Reads identified: '{filename}' -> renamed to '{reads_filename}'\")\n",
        "        found_reads = True\n",
        "    elif filename.endswith(\".fasta\") or filename.endswith(\".fa\") or filename.endswith(\".fna\"):\n",
        "        os.rename(filename, ref_filename)\n",
        "        print(f\"âœ… Reference identified: '{filename}' -> renamed to '{ref_filename}'\")\n",
        "        found_ref = True\n",
        "\n",
        "if not found_reads:\n",
        "    print(\"âŒ ERROR: No .fastq file found! Please re-run and upload your sequencing data.\")\n",
        "if not found_ref:\n",
        "    print(\"âŒ ERROR: No .fasta reference file found! Please re-run and upload your reference genome.\")\n",
        "\n",
        "if found_reads and found_ref:\n",
        "    print(\"\\nðŸŽ‰ Data ready for analysis!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwjPCcrz2Avy"
      },
      "source": [
        "## Part 3: Basic Statistics (The \"Table 1\" of Genomics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s_vkmAx2Avy"
      },
      "outputs": [],
      "source": [
        "# @title Step 3: Parse and Calculate Basic Stats\n",
        "def calculate_fastq_stats(fastq_file):\n",
        "    lengths = []\n",
        "    qualities = []\n",
        "    print(f\"Parsing {fastq_file}...\")\n",
        "\n",
        "    # Iterate through every read in the file\n",
        "    for record in SeqIO.parse(fastq_file, \"fastq\"):\n",
        "        lengths.append(len(record))\n",
        "        avg_q = np.mean(record.letter_annotations[\"phred_quality\"])\n",
        "        qualities.append(avg_q)\n",
        "\n",
        "    lengths = np.array(lengths)\n",
        "    qualities = np.array(qualities)\n",
        "\n",
        "    if len(lengths) == 0:\n",
        "        print(\"âš ï¸ Warning: File is empty or not in FASTQ format.\")\n",
        "        return {}, [], []\n",
        "\n",
        "    # Calculate N50 (Weighted Median)\n",
        "    sorted_lengths = np.sort(lengths)\n",
        "    cumsum = np.cumsum(sorted_lengths)\n",
        "    n50_idx = np.searchsorted(cumsum, cumsum[-1] / 2)\n",
        "    n50 = sorted_lengths[n50_idx]\n",
        "\n",
        "    stats = {\n",
        "        \"Total Reads\": len(lengths),\n",
        "        \"Total Yield (bp)\": np.sum(lengths),\n",
        "        \"Mean Length (bp)\": int(np.mean(lengths)),\n",
        "        \"Max Length (bp)\": np.max(lengths),\n",
        "        \"N50 (bp)\": int(n50),\n",
        "        \"Mean Q-Score\": np.round(np.mean(qualities), 2)\n",
        "    }\n",
        "    return stats, lengths, qualities\n",
        "\n",
        "# Run analysis on the renamed file\n",
        "raw_stats, raw_lengths, raw_quals = calculate_fastq_stats(reads_filename)\n",
        "\n",
        "print(\"\\n--- Raw Data Statistics ---\")\n",
        "display(pd.DataFrame(raw_stats, index=[\"Value\"]).T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez3rsYHE2Avz"
      },
      "source": [
        "## Part 4: Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zcqdb322Avz"
      },
      "outputs": [],
      "source": [
        "# @title Step 4: Visualize Read Length vs. Quality\n",
        "if len(raw_lengths) > 0:\n",
        "    df = pd.DataFrame({\n",
        "        \"Read Length (bp)\": raw_lengths,\n",
        "        \"Mean Quality (Phred)\": raw_quals\n",
        "    })\n",
        "\n",
        "    # Plot 1: Length vs Quality Hexbin\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.jointplot(x=\"Read Length (bp)\", y=\"Mean Quality (Phred)\", data=df, kind=\"hex\", color=\"#4CB391\")\n",
        "    plt.suptitle(\"Read Length vs. Quality Score\", y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot 2: Length Distribution\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.histplot(raw_lengths, log_scale=True, color=\"skyblue\")\n",
        "    plt.title(\"Read Length Distribution (Log Scale)\")\n",
        "    plt.xlabel(\"Read Length (bp)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data to plot.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaP57ELL2Avz"
      },
      "source": [
        "## Part 5: Quality Filtering\n",
        "Real data often contains \"junk\" reads (too short or low quality). We will filter them out.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdoaA7aL2Av0"
      },
      "outputs": [],
      "source": [
        "# @title Step 5: Filter the Data\n",
        "# FILTER SETTINGS\n",
        "min_length = 1000  # Minimum length in base pairs\n",
        "min_quality = 10   # Minimum average Phred quality score (Q10 = 90% accuracy)\n",
        "\n",
        "filtered_output = \"filtered_reads.fastq\"\n",
        "filtered_records = []\n",
        "\n",
        "print(f\"Filtering reads (Min Length: {min_length}, Min Q: {min_quality})...\")\n",
        "\n",
        "for record in SeqIO.parse(reads_filename, \"fastq\"):\n",
        "    avg_q = np.mean(record.letter_annotations[\"phred_quality\"])\n",
        "    if len(record) >= min_length and avg_q >= min_quality:\n",
        "        filtered_records.append(record)\n",
        "\n",
        "# Save filtered file\n",
        "with open(filtered_output, \"w\") as output_handle:\n",
        "    SeqIO.write(filtered_records, output_handle, \"fastq\")\n",
        "\n",
        "print(f\"âœ… Filtering complete. Saved to: {filtered_output}\")\n",
        "print(f\"Reads kept: {len(filtered_records)} / {raw_stats['Total Reads']}\")\n",
        "print(f\"Reads discarded: {raw_stats['Total Reads'] - len(filtered_records)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw1_kNzk2Av0"
      },
      "source": [
        "## Part 6: Verify Improvements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20jx1e3q2Av1"
      },
      "outputs": [],
      "source": [
        "# @title Step 6: Comparative Analysis\n",
        "filt_stats, _, _ = calculate_fastq_stats(filtered_output)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Raw Data\": raw_stats,\n",
        "    \"Filtered Data\": filt_stats\n",
        "})\n",
        "print(\"\\n--- Improvement Analysis ---\")\n",
        "display(comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04y3RoZk2Av1"
      },
      "source": [
        "## Part 7: Map Reads to Reference\n",
        "We will use `minimap2` to align our filtered reads to the reference genome you uploaded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clN9MyWg2Av1"
      },
      "outputs": [],
      "source": [
        "# @title Step 7: Map Reads (Minimap2)\n",
        "# Check if reference exists\n",
        "if not os.path.exists(ref_filename):\n",
        "    print(\"âŒ ERROR: Reference file missing. Please go back to Step 2.\")\n",
        "else:\n",
        "    print(f\"Mapping {filtered_output} to {ref_filename}...\")\n",
        "\n",
        "    # 1. Align reads (-ax map-ont is optimized for Nanopore)\n",
        "    !minimap2 -ax map-ont {ref_filename} {filtered_output} > aligned.sam\n",
        "\n",
        "    # 2. Convert to BAM, Sort, and Index\n",
        "    print(\"Processing alignment files...\")\n",
        "    !samtools view -S -b aligned.sam > aligned.bam\n",
        "    !samtools sort aligned.bam -o aligned.sorted.bam\n",
        "    !samtools index aligned.sorted.bam\n",
        "\n",
        "    print(\"âœ… Mapping complete! Output: aligned.sorted.bam\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0P__xsi2Av2"
      },
      "source": [
        "## Part 8: Visualize Coverage Depth\n",
        "Let's see how many reads covered each part of the chloroplast genome.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPWhtcxO2Av2"
      },
      "outputs": [],
      "source": [
        "# @title Step 8: Plot Genome Coverage\n",
        "if os.path.exists(\"aligned.sorted.bam\"):\n",
        "    !samtools depth aligned.sorted.bam > coverage.txt\n",
        "\n",
        "    # Check if coverage file is empty (mapping failed?)\n",
        "    if os.stat(\"coverage.txt\").st_size == 0:\n",
        "        print(\"âš ï¸ Warning: Coverage file is empty. Your reads might not match the reference genome!\")\n",
        "    else:\n",
        "        cov_df = pd.read_csv(\"coverage.txt\", sep=\"\\t\", names=[\"Chrom\", \"Position\", \"Depth\"])\n",
        "        mean_depth = cov_df[\"Depth\"].mean()\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.fill_between(cov_df[\"Position\"], cov_df[\"Depth\"], color=\"#2c3e50\", alpha=0.3)\n",
        "        plt.plot(cov_df[\"Position\"], cov_df[\"Depth\"], color=\"#2c3e50\", linewidth=1)\n",
        "        plt.axhline(mean_depth, color='red', linestyle='--', label=f\"Mean: {mean_depth:.0f}x\")\n",
        "\n",
        "        plt.title(\"Genome Coverage Map\")\n",
        "        plt.xlabel(\"Genome Position (bp)\")\n",
        "        plt.ylabel(\"Read Depth (x)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"âŒ BAM file missing. Run Step 7 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXGfexo82Av2"
      },
      "source": [
        "## Part 9: Consensus Genome Assembly\n",
        "Create the final consensus sequence based on the mapping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldT7bCJI2Av2"
      },
      "outputs": [],
      "source": [
        "# @title Step 9: Call Variants & Assembly\n",
        "print(\"1. Calling Variants...\")\n",
        "!bcftools mpileup -f {ref_filename} aligned.sorted.bam | bcftools call -mv -Oz -o calls.vcf.gz\n",
        "\n",
        "print(\"2. Indexing...\")\n",
        "!bcftools index calls.vcf.gz\n",
        "\n",
        "print(\"3. Creating Consensus...\")\n",
        "!bcftools consensus -f {ref_filename} calls.vcf.gz > final_consensus.fasta\n",
        "\n",
        "print(\"\\nâœ… ASSEMBLY COMPLETE: final_consensus.fasta\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN4ggzm52Av3"
      },
      "source": [
        "## Part 10: Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OTj1TcU2Av3"
      },
      "outputs": [],
      "source": [
        "# @title Step 10: Zip and Download\n",
        "print(\"Zipping files...\")\n",
        "!zip -r analysis_results.zip final_consensus.fasta coverage.txt aligned.sorted.bam calls.vcf.gz\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"analysis_results.zip\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}